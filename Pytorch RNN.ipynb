{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import autograd\n",
    "torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to initialize rnn\n",
    "\n",
    "basic_cell=nn.RNN(input_size=4,hidden_size=2,batch_first=True)\n",
    "gru_cell=nn.GRU(input_size=4,hidden_size=2,batch_first=True)\n",
    "lstm_cell=nn.LSTM(input_size=4,hidden_size=2,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs= (batch_size,seq_length,input_size) with batch_first=True\n",
    "#hidden=(num_layers,batch_size,hidden_size)\n",
    "#out,hidden=basic_cell(inputs,hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder as OHE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "clf=LabelEncoder()\n",
    "res=clf.fit_transform(['h','e','l','l','o'])\n",
    "clf=OHE()\n",
    "res=res.reshape(-1,1)\n",
    "final_res=clf.fit_transform(res).toarray()\n",
    "res2=pd.get_dummies(['h','e','l','l','o'])\n",
    "final_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=LabelEncoder()\n",
    "res=clf.fit_transform(['p','y','t','o','o'])\n",
    "clf=OHE()\n",
    "res=res.reshape(-1,1)\n",
    "final_res_2=clf.fit_transform(res).toarray()\n",
    "final_res_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs=autograd.Variable(torch.tensor([[final_res[0]]])).float()\n",
    "inputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to initialize the hidden state\n",
    "#(num_layers*num_directions,batch_size,hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden=autograd.Variable(torch.randn(1,1,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "out,hiddens=basic_cell(inputs,hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 4])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To pass multiple sequences at same time\n",
    "inputs=autograd.Variable(torch.tensor([final_res])).float()\n",
    "inputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden=autograd.Variable(torch.randn(1,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "out,hiddens=basic_cell(inputs,hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1379,  0.0754]]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiddens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use batch_size as well in rnn\n",
    "inputs=autograd.Variable(torch.tensor([final_res,final_res_2])).float()#inputs= (batch_size,seq_length,input_size) with batch_first=True\n",
    "hidden=autograd.Variable(torch.randn(1,2,2)) ##hidden=(num_layers,batch_size,hidden_size)\n",
    "out,hiddens=basic_cell(inputs,hidden)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5246,  0.8300],\n",
       "         [-0.5455,  0.2882],\n",
       "         [-0.2801, -0.3252],\n",
       "         [-0.4187,  0.0914],\n",
       "         [ 0.1563,  0.0322]],\n",
       "\n",
       "        [[-0.3019,  0.9758],\n",
       "         [ 0.3931, -0.2948],\n",
       "         [-0.3779,  0.4290],\n",
       "         [-0.6150,  0.5095],\n",
       "         [-0.6095,  0.3724]]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
